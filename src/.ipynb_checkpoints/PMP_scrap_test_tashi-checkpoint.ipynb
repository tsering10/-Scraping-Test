{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "from urllib.error import HTTPError\n",
    "import random\n",
    "import time\n",
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.90 Safari/537.36'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_page_info():\n",
    "    '''\n",
    "    scrap all the comments and notes for insurer \"Ag2r La Mondiale\" for their product \"Mutuelle santé\".\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    comment_gen = []\n",
    "    comment_plus = []\n",
    "    comment_moin = []\n",
    "    comment_date = []\n",
    "    Niveaux_des_prix = []\n",
    "    Qualité_du_service_client = []\n",
    "    Qualité_des_garanties = []\n",
    "    Satisfaction = []\n",
    "\n",
    "    \n",
    "    # Get all the page urls \n",
    "    pages = []\n",
    "    for i in range(1, 10):\n",
    "        url = 'https://www.opinion-assurances.fr/assureur-ag2r-assurance-sante-page{}.html'.format(i)\n",
    "        pages.append(url)\n",
    "        \n",
    "    # For every page in the interval 1 to 9\n",
    "    \n",
    "    for page in pages:\n",
    "        try: \n",
    "            response = requests.get(page,headers=headers)\n",
    "            # Pause the loop\n",
    "            time.sleep(random.uniform(1.0, 2.0))\n",
    "            print(page, response.status_code)\n",
    "            print('----------------------------------------------------------------------------')\n",
    "        except HTTPError as e:\n",
    "            print(e)\n",
    "            \n",
    "        # Parse the content of the request with BeautifulSoup\n",
    "        page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Get all the urls of each page \n",
    "        \n",
    "        internal_urls=[]\n",
    "        for elem in page_html.find_all('a',attrs={\"class\" :\"pull-right\"}):\n",
    "            # append all the urls in a list \n",
    "            internal_urls.append(elem.get('href'))\n",
    "            \n",
    "        # Build absolute urls\n",
    "        \n",
    "        absolute_urls =['https://www.opinion-assurances.fr'+ elem for elem in internal_urls if 'ag2r' in elem]\n",
    "        \n",
    "        \n",
    "        #  crawl for every internal url\n",
    "        \n",
    "        for url in absolute_urls:\n",
    "            time.sleep(random.uniform(1.0, 1.0))\n",
    "        \n",
    "            response = requests.get(url)\n",
    "            if response.status_code != 200: return\n",
    "            print(url, response.status_code)\n",
    "            \n",
    "            # Parse the html using beautiful soap and store in variable `internal_page_html`\n",
    "            internal_page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            \n",
    "            # This block of code is use to scrap all the Commentaire général\n",
    "            comment_g = internal_page_html.find('div',attrs={\"class\":\"well break\"})\n",
    "\n",
    "            if comment_g is not None:\n",
    "                comment_gen.append(comment_g.h2.text.strip())\n",
    "                #print(comment_g.h2.text.strip())\n",
    "            else:\n",
    "                comment_gen.append(\"-\")\n",
    "                \n",
    "            # This block of code is use scrap all the Commentaire “plus”\n",
    "        \n",
    "            comment_p = internal_page_html.find('div',attrs={\"class\":\"plus\"})\n",
    "            if comment_p is not None:\n",
    "                comment_plus.append(comment_p.h3.text.strip())\n",
    "            else:\n",
    "                comment_plus.append(\"-\")\n",
    "                \n",
    "                \n",
    "            # This block of code is use to scrap all the Commentaire “moins” \n",
    "            \n",
    "            comment_m = internal_page_html.find('div',attrs={\"class\":\"moins\"})\n",
    "        \n",
    "            if comment_m is not None:\n",
    "                comment_moin.append(comment_m.h3.text.strip())\n",
    "            else:\n",
    "                comment_moin.append(\"-\")\n",
    "                \n",
    "                \n",
    "            # This block of code is use to scrap all the Date du commentaire\n",
    "\n",
    "       \n",
    "            for com_date in internal_page_html.find_all('span',attrs={\"id\" :\"MC_lbDate\"}):\n",
    "                comment_date.append(com_date.text.strip())\n",
    "                \n",
    "                \n",
    "            # This block of code is use to extract all the Niveaux_des_prix \n",
    "        \n",
    "        \n",
    "            niveaux_prix = internal_page_html.find_all('div',attrs={\"class\" :\"alf_stackLevel alf_stackLevelReadOnly\"})[0]\n",
    "            niveaux_prix_rating= niveaux_prix.find('div',attrs={\"class\" :\"alf_label\"})\n",
    "            Niveaux_des_prix.append(niveaux_prix_rating.text.strip()) \n",
    "\n",
    "            # This block of code is use to extract all the Qualité du service client\n",
    "\n",
    "            service_client = internal_page_html.find_all('div',attrs={\"class\" :\"alf_stackLevel alf_stackLevelReadOnly\"})[1]\n",
    "            service_client_rating = service_client.find('div',attrs={\"class\" :\"alf_label\"})\n",
    "            Qualité_du_service_client.append(service_client_rating.text.strip())\n",
    "\n",
    "\n",
    "             # This blcok of code is use to extract all the Qualité_des_garanties \n",
    "\n",
    "            qualite_garanties = internal_page_html.find_all('div',attrs={\"class\" :\"alf_stackLevel alf_stackLevelReadOnly\"})[2]\n",
    "            qualite_garanties_rating = qualite_garanties.find('div',attrs={\"class\" :\"alf_label\"})\n",
    "            Qualité_des_garanties.append(qualite_garanties_rating.text.strip())\n",
    "\n",
    "\n",
    "             # This blcok of code is use to extract all the Satisfaction\n",
    "\n",
    "            satisfaction= internal_page_html.find_all('div',attrs={\"class\" :\"alf_stackLevel alf_stackLevelReadOnly\"})[3]\n",
    "            satisfaction_rating= satisfaction.find('div',attrs={\"class\" :\"alf_label\"})\n",
    "            Satisfaction.append(satisfaction_rating.text.strip())\n",
    "            \n",
    "    #  Verfiy the length of the list \n",
    "    \n",
    "    print(len(comment_gen),len(comment_plus),len(comment_moin),len(comment_date),len(Niveaux_des_prix), len(Qualité_du_service_client),len(Satisfaction), len(Qualité_des_garanties))\n",
    "    \n",
    "    # Create a python dictinary \n",
    "    page_info = {\n",
    "        'com_general':comment_gen,\n",
    "        'com_plus': comment_plus,\n",
    "        'com_moin': comment_moin,\n",
    "        'date': comment_date,\n",
    "        \"niveaux des prix\":Niveaux_des_prix,\n",
    "        \"qualité_du_service_client\": Qualité_du_service_client,\n",
    "        \"qualité_des_garanties\":Qualité_des_garanties,\n",
    "        \"satisfaction\":Satisfaction,\n",
    "        \"assureur\": \"Ag2r La Mondiale\",\n",
    "        \"produit\": \"vie\"\n",
    "    }\n",
    "    \n",
    "    return page_info \n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToExcel(data):\n",
    "    '''\n",
    "    Take the dict of results and write to an excel file.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    data_frame = pd.DataFrame(data)\n",
    "    data_frame.to_excel(r'/home/tashitsering/Desktop/PMP_test_tashi/data/output.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.opinion-assurances.fr/assureur-ag2r-assurance-sante-page1.html 200\n",
      "----------------------------------------------------------------------------\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-102184.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-101844.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-101814.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-101798.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-101632.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-101553.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-101188.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-101123.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-101120.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-101040.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-100828.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-100744.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-100706.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-100684.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-100650.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-100547.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-100427.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-100262.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-100073.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-99755.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-99696.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-97500.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-97339.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-97299.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-97222.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-97063.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-96866.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-96863.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-96673.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-96619.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-96364.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-96308.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-96264.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-96206.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-96161.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-95447.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-95286.html 200\n",
      "https://www.opinion-assurances.fr/ag2r-assurance-sante-avis-94994.html 200\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    all_data = get_all_page_info()\n",
    "    writeToExcel(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
